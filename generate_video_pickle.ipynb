{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17658,
     "status": "ok",
     "timestamp": 1754886525114,
     "user": {
      "displayName": "Tingkai Xue",
      "userId": "03772826909779438587"
     },
     "user_tz": -480
    },
    "id": "TncaZfSLsqDj",
    "outputId": "862503c4-910d-43dc-ba38-d8fac226bf75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import sys\n",
    "dir = '/content/drive/MyDrive/ARIA'\n",
    "sys.path.append(dir)\n",
    "\n",
    "import os\n",
    "os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = 'false'\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_rbjBJXztbiE"
   },
   "source": [
    "# Recurrent Closure\n",
    "\n",
    "$$\\begin{align}\n",
    "c^{t+1} &= c^t + A(c^t) + D(c^t) + R(c^t) + F_1 (c^t, A(c^t), D(c^t), T, h^t)\\\\\n",
    "h^{t+1} &= F_2 (c^{t+1}, h^t)\n",
    "\\end{align} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 3602,
     "status": "ok",
     "timestamp": 1754886528708,
     "user": {
      "displayName": "Tingkai Xue",
      "userId": "03772826909779438587"
     },
     "user_tz": -480
    },
    "id": "38-Lq_9EtVps"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import jax\n",
    "import optax\n",
    "from flax import linen as nn\n",
    "from jax import numpy as jnp\n",
    "from flax.training import train_state  # Useful dataclass to keep train state\n",
    "import flax\n",
    "\n",
    "from functools import partial\n",
    "import pickle\n",
    "\n",
    "from numerical_methods import physics, ssim\n",
    "import dataset.read_data_to_grid as rdtg\n",
    "\n",
    "\n",
    "os.environ[\"XLA_PYTHON_CLIENT_PREALLOCATE\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 23889,
     "status": "ok",
     "timestamp": 1754886552600,
     "user": {
      "displayName": "Tingkai Xue",
      "userId": "03772826909779438587"
     },
     "user_tz": -480
    },
    "id": "KCVz9zXNtoyw"
   },
   "outputs": [],
   "source": [
    "dx, dy = 0.5, 0.5\n",
    "ny, nx = 26, 49\n",
    "dt = 0.4\n",
    "NSUBSTEPS = 4\n",
    "\n",
    "with open(f'{dir}/dataset/dataset_v2.pickle', 'rb') as handle:\n",
    "  dataset = pickle.load(handle)\n",
    "\n",
    "# train_set = [6, 12,  0, 8, 21,  2,  7, 15, 17, 10, 19,  5, 23, 13,  4]\n",
    "train_set = list(range(len(dataset['SMOKE_FIELD'])))\n",
    "\n",
    "INFLOW_LOCS = dataset['INFLOW_LOCS'][train_set,]\n",
    "FLOW_TIMES = [jnp.concatenate((jnp.zeros((1,)),jnp.array(dataset['FLOW_TIMES'][i]))) for i in train_set]\n",
    "SMOKE_FIELD = [jnp.concatenate((jnp.zeros((1,ny,nx)), jnp.array(dataset['SMOKE_FIELD'][i])), axis=0) for i in train_set]\n",
    "VELOCITY = dataset['VELOCITY']\n",
    "REL_LOC = dataset['rel_loc']\n",
    "TERRAIN = dataset['TERRAIN']\n",
    "SPLINE_TCK = [dataset['SPLINE_TCK'][i] for i in train_set]\n",
    "\n",
    "INFLOW_VALS = []\n",
    "for set_idx in range(len(SMOKE_FIELD)):\n",
    "  y,x = INFLOW_LOCS[set_idx]\n",
    "  inflow_for_set = []\n",
    "  for i in range(len(REL_LOC)):\n",
    "    rel_y, rel_x = REL_LOC[i]\n",
    "    inflow_for_set_for_loc = []\n",
    "    for nt in range(1, 6001):\n",
    "      val = scipy.interpolate.splev(nt*dt, SPLINE_TCK[set_idx][i])\n",
    "      inflow_for_set_for_loc.append(val)\n",
    "    inflow_for_set.append(inflow_for_set_for_loc)\n",
    "  INFLOW_VALS.append(inflow_for_set)\n",
    "\n",
    "INFLOW_VALS = jnp.array(INFLOW_VALS)\n",
    "\n",
    "# FILENAME_PREFIX = f'{dir}/15042025_phase3_cnnfc'\n",
    "\n",
    "diff_x_mask = jnp.logical_and(TERRAIN[:,1:],TERRAIN[:,:-1])\n",
    "diff_y_mask = jnp.logical_and(TERRAIN[1:,:],TERRAIN[:-1,:])\n",
    "\n",
    "diff_x_grad_x_mask = jnp.logical_and(diff_x_mask[:,1:],diff_x_mask[:,:-1])\n",
    "diff_x_grad_y_mask = jnp.logical_and(diff_x_mask[1:,:],diff_x_mask[:-1,:])\n",
    "diff_y_grad_x_mask = jnp.logical_and(diff_y_mask[:,1:],diff_y_mask[:,:-1])\n",
    "diff_y_grad_y_mask = jnp.logical_and(diff_y_mask[1:,:],diff_y_mask[:-1,:])\n",
    "\n",
    "diff_x_mask = diff_x_mask.astype(jnp.float32)\n",
    "diff_y_mask = diff_y_mask.astype(jnp.float32)\n",
    "diff_x_grad_x_mask = diff_x_grad_x_mask.astype(jnp.float32)\n",
    "diff_x_grad_y_mask = diff_x_grad_y_mask.astype(jnp.float32)\n",
    "diff_y_grad_x_mask = diff_y_grad_x_mask.astype(jnp.float32)\n",
    "diff_y_grad_y_mask = diff_y_grad_y_mask.astype(jnp.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 864,
     "status": "ok",
     "timestamp": 1754886553456,
     "user": {
      "displayName": "Tingkai Xue",
      "userId": "03772826909779438587"
     },
     "user_tz": -480
    },
    "id": "qG6UNSizhJur",
    "outputId": "c8855eb7-3fc0-4ce0-decd-d34a7ad3099a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "792 rows of data read\n",
      "791 data points used for grid\n",
      "Checksum: 7.059849280200001\n"
     ]
    }
   ],
   "source": [
    "grid = rdtg.read_data(f\"{dir}/dataset/turb_vis.txt\")\n",
    "turb_vis = rdtg.extract_xyz_to_array(grid, x_range=(0, 48), y_range=(0, 25), z_range=(1,1), yxz=True)\n",
    "turb_diff = jnp.array(turb_vis/0.7)\n",
    "\n",
    "turb_diff_x = ((turb_diff[:,1:] + turb_diff[:,:-1])/2).squeeze()\n",
    "turb_diff_y = ((turb_diff[1:,:] + turb_diff[:-1,:])/2).squeeze()\n",
    "\n",
    "turb_diff_x = jnp.where(diff_x_mask, turb_diff_x, 0)\n",
    "turb_diff_y = jnp.where(diff_y_mask, turb_diff_y, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6TRjvB3TzwwS"
   },
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJYiPpnCtqh4"
   },
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1754886553476,
     "user": {
      "displayName": "Tingkai Xue",
      "userId": "03772826909779438587"
     },
     "user_tz": -480
    },
    "id": "nCIiOAGetpVP"
   },
   "outputs": [],
   "source": [
    "class ClosureNet(nn.Module):\n",
    "    def setup(self):\n",
    "        # for decoding the hidden state\n",
    "        self.convTrans1 = nn.ConvTranspose(features=128, kernel_size=(3, 2), strides=(3, 2), padding='SAME')\n",
    "        self.conv11 = nn.Conv(features=128, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.convTrans2 = nn.ConvTranspose(features=64, kernel_size=(2, 2), strides=(2, 2), padding='SAME')\n",
    "        self.conv21 = nn.Conv(features=64, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.convTrans3 = nn.ConvTranspose(features=32, kernel_size=(2, 3), strides=(2, 3), padding='SAME')\n",
    "        self.conv31 = nn.Conv(features=32, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.convTrans4 = nn.ConvTranspose(features=16, kernel_size=(2, 3), strides=(2, 3), padding='SAME')\n",
    "        self.conv41 = nn.Conv(features=16, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "\n",
    "        # for transforming the output\n",
    "        self.conv1 = nn.Conv(features=32, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.conv2 = nn.Conv(features=32, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.conv3 = nn.Conv(features=1, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "\n",
    "\n",
    "    def __call__(self, x, h):\n",
    "        # h is a list of hidden states\n",
    "        dec = jnp.concatenate((h[0],h[1],h[2],h[3]))\n",
    "        dec = jnp.expand_dims(dec, axis=(0,1))\n",
    "\n",
    "        dec = self.convTrans1(dec)                          # (3,2)\n",
    "        dec = nn.leaky_relu(dec, negative_slope=0.01)       # (3,2)\n",
    "        dec = nn.leaky_relu(self.conv11(dec), negative_slope=0.01)+dec       # (3,2)\n",
    "\n",
    "        dec = self.convTrans2(dec)                          # (6,4)\n",
    "        dec = nn.leaky_relu(dec, negative_slope=0.01)       # (6,4)\n",
    "        dec = jnp.pad(dec, ((0, 0), (0, 1), (0, 0)), mode='edge')        # (6,5)\n",
    "        dec = nn.leaky_relu(self.conv21(dec), negative_slope=0.01)+dec       # (6,5)\n",
    "\n",
    "        dec = self.convTrans3(dec)                                       # (12,15)\n",
    "        dec = nn.leaky_relu(dec, negative_slope=0.01)                    # (12,15)\n",
    "        dec = jnp.pad(dec, ((0, 1), (1, 0), (0, 0)), mode='edge')        # (13,16)\n",
    "        dec = nn.leaky_relu(self.conv31(dec), negative_slope=0.01)+dec   # (13,16)\n",
    "\n",
    "        dec = self.convTrans4(dec)                                       # (26,48)\n",
    "        dec = jnp.pad(dec, ((0, 0), (0, 1), (0, 0)), mode='edge')        # (26,49)\n",
    "        dec = nn.leaky_relu(self.conv41(dec), negative_slope=0.01)+dec   # (26,49)\n",
    "\n",
    "        output = jnp.concatenate((dec, x), axis=-1)\n",
    "        output = nn.leaky_relu(self.conv1(output), negative_slope=0.01) + jnp.pad(output, ((0,0),(0,0),(6,0)))\n",
    "        output = nn.leaky_relu(self.conv2(output), negative_slope=0.01) + output\n",
    "        output = self.conv3(output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 41,
     "status": "ok",
     "timestamp": 1754886553526,
     "user": {
      "displayName": "Tingkai Xue",
      "userId": "03772826909779438587"
     },
     "user_tz": -480
    },
    "id": "SJQBf0a9tvCp"
   },
   "outputs": [],
   "source": [
    "class HiddenNet(nn.Module):\n",
    "    def setup(self):\n",
    "        # to encode the scalar field\n",
    "        self.conv1 = nn.Conv(features=16, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.conv11 = nn.Conv(features=16, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.conv2 = nn.Conv(features=32, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.conv21 = nn.Conv(features=32, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.conv3 = nn.Conv(features=64, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.conv31 = nn.Conv(features=64, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.conv4 = nn.Conv(features=128, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.conv41 = nn.Conv(features=128, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "\n",
    "        self.lstm1 = nn.OptimizedLSTMCell(features=128)\n",
    "        self.lstm2 = nn.OptimizedLSTMCell(features=128)\n",
    "        self.lstm3 = nn.OptimizedLSTMCell(features=128)\n",
    "        self.lstm4 = nn.OptimizedLSTMCell(features=128)\n",
    "\n",
    "\n",
    "    def __call__(self, x, h, c):\n",
    "        x = self.conv1(x)\n",
    "        x = nn.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.conv11(x)\n",
    "        x = nn.leaky_relu(x, negative_slope=0.01)\n",
    "        x = nn.max_pool(x, window_shape=(2, 3), strides=(2, 3))\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = nn.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.conv21(x)\n",
    "        x = nn.leaky_relu(x, negative_slope=0.01)\n",
    "        x = nn.max_pool(x, window_shape=(2, 3), strides=(2, 3))\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = nn.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.conv31(x)\n",
    "        x = nn.leaky_relu(x, negative_slope=0.01)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = nn.leaky_relu(x, negative_slope=0.01)\n",
    "        x = self.conv41(x)\n",
    "        x = nn.leaky_relu(x, negative_slope=0.01)\n",
    "        x = nn.max_pool(x, window_shape=(2, 2), strides=(2, 2))\n",
    "        # x now contains the encoded current smoke state (input)\n",
    "\n",
    "        # correction: lstm takes (c,h)\n",
    "        (c1, h1), x1 = self.lstm1((c[0], h[0]), x)\n",
    "        (c2, h2), x2 = self.lstm2((c[1], h[1]), x1)\n",
    "        (c3, h3), x3 = self.lstm3((c[2], h[2]), x2)\n",
    "        (c4, h4), x4 = self.lstm4((c[3], h[3]), x3)\n",
    "\n",
    "        return jnp.array([h1.squeeze(), h2.squeeze(), h3.squeeze(), h4.squeeze()]), \\\n",
    "               jnp.array([c1.squeeze(), c2.squeeze(), c3.squeeze(), c4.squeeze()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1754886553531,
     "user": {
      "displayName": "Tingkai Xue",
      "userId": "03772826909779438587"
     },
     "user_tz": -480
    },
    "id": "bU8cBQyZWCyX"
   },
   "outputs": [],
   "source": [
    "class InflowNet(nn.Module):\n",
    "    def setup(self):\n",
    "        self.conv1 = nn.Conv(features=8, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.conv2 = nn.Conv(features=16, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.conv3 = nn.Conv(features=32, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.conv4 = nn.Conv(features=64, kernel_size=(3,3), strides=1, padding='SAME', kernel_init=nn.initializers.xavier_uniform())\n",
    "\n",
    "        self.fc1 = nn.Dense(features=64, kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.fc2 = nn.Dense(features=64, kernel_init=nn.initializers.xavier_uniform())\n",
    "        self.fc3 = nn.Dense(features=4, kernel_init=nn.initializers.xavier_uniform())\n",
    "\n",
    "    def __call__(self, x):\n",
    "        # Encoder\n",
    "        enc1 = self.conv1(x)                                  # (26,49)\n",
    "        enc1 = nn.leaky_relu(enc1, negative_slope=0.01)       # (26,49)\n",
    "\n",
    "        enc2 = nn.max_pool(enc1, (2, 3), strides=(2, 3))      # (13,16)\n",
    "        enc2 = self.conv2(enc2)                               # (13,16)\n",
    "        enc2 = nn.leaky_relu(enc2, negative_slope=0.01)       # (13,16)\n",
    "\n",
    "        enc3 = nn.max_pool(enc2, (2, 3), strides=(2, 3))      # (6,5)\n",
    "        enc3 = self.conv3(enc3)                               # (6,5)\n",
    "        enc3 = nn.leaky_relu(enc3, negative_slope=0.01)       # (6,5)\n",
    "\n",
    "        enc4 = nn.max_pool(enc3, (2, 2), strides=(2, 2))      # (3,2)\n",
    "        enc4 = self.conv4(enc4)                               # (3,2)\n",
    "        enc4 = nn.leaky_relu(enc4, negative_slope=0.01)       # (3,2)\n",
    "\n",
    "        bottleneck = nn.max_pool(enc4, (3, 2), strides=(3, 2))            # (1,1)\n",
    "\n",
    "        output = nn.leaky_relu(self.fc1(bottleneck.squeeze()))\n",
    "        output = nn.leaky_relu(self.fc2(output))\n",
    "        output = self.fc3(output)\n",
    "        return 10**(-5+jnp.tanh(output))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "klah0g4NzniB"
   },
   "source": [
    "## Phase 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NuBmXkfyt7U-"
   },
   "source": [
    "## Simulation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1754886553535,
     "user": {
      "displayName": "Tingkai Xue",
      "userId": "03772826909779438587"
     },
     "user_tz": -480
    },
    "id": "sL6HNBJPkkbw"
   },
   "outputs": [],
   "source": [
    "hidden_net = HiddenNet()\n",
    "closure_net = ClosureNet()\n",
    "inflow_net = InflowNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1754886553541,
     "user": {
      "displayName": "Tingkai Xue",
      "userId": "03772826909779438587"
     },
     "user_tz": -480
    },
    "id": "xkTfUAuF1Y9e"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def conv_diff_single_step(params,\n",
    "                          smoke_initial: jnp.array,\n",
    "                          hidden_state: jnp.array,\n",
    "                          cell_state: jnp.array,\n",
    "                          velocity: jnp.array,\n",
    "                          time_curr: float,\n",
    "                          inflow_loc: jnp.array,\n",
    "                          inflow_vals: jnp.array,\n",
    "                          terrain: jnp.array,\n",
    "                          dt: float):\n",
    "    y,x = inflow_loc\n",
    "    inflow_marker = jnp.zeros((26,49))\n",
    "    for i in range(len(REL_LOC)):\n",
    "        rel_y, rel_x = REL_LOC[i]\n",
    "\n",
    "        # set smoke at inflow locations\n",
    "        inflow_marker = inflow_marker.at[y+rel_y, x+rel_x].set(1.0)\n",
    "\n",
    "    # compute inflow term\n",
    "    input = jnp.stack((terrain,\n",
    "                       velocity[0,:,:],\n",
    "                       velocity[1,:,:],\n",
    "                       velocity[2,:,:],\n",
    "                       jnp.pad(params['diffusivity_x'], ((0, 0), (1, 0))),\n",
    "                       jnp.pad(params['diffusivity_y'], ((1, 0), (0, 0))),\n",
    "                       inflow_marker), axis=-1) #(4,)\n",
    "    inflow = inflow_net.apply({'params': params['inflow']}, input)\n",
    "    inflow_term = jnp.zeros((26,49))\n",
    "    for i in range(len(REL_LOC)):\n",
    "        rel_y, rel_x = REL_LOC[i]\n",
    "        inflow_term = inflow_term.at[y+rel_y, x+rel_x].set(inflow[i])\n",
    "\n",
    "    smoke_pred = smoke_initial\n",
    "    for _ in range(NSUBSTEPS):\n",
    "      advection_step = physics.advect_fvm(field=smoke_pred,\n",
    "                                              velocity=velocity,\n",
    "                                              dx=dx,\n",
    "                                              dy=dy) * dt/NSUBSTEPS\n",
    "\n",
    "      diffusion_step = physics.diffuse_2d_fvm(field=smoke_pred,\n",
    "                                              diffusivity_x=params['diffusivity_x'],\n",
    "                                              diffusivity_y=params['diffusivity_y'],\n",
    "                                              dx=dx,\n",
    "                                              dy=dy) * dt/NSUBSTEPS\n",
    "\n",
    "      inflow_step = inflow_term * dt/NSUBSTEPS\n",
    "      smoke_pred = smoke_pred + advection_step + diffusion_step + inflow_step\n",
    "\n",
    "    # compute closure term\n",
    "    smoke_mean = jnp.mean(smoke_initial)\n",
    "    eps = 1e-8\n",
    "    smoke_std = jnp.std(smoke_initial)\n",
    "    smoke_std_safe = jnp.where(smoke_std > eps, smoke_std, eps)\n",
    "    input = jnp.stack(((smoke_initial-smoke_mean)/smoke_std_safe,\n",
    "                        terrain * smoke_mean,\n",
    "                        terrain * smoke_std,\n",
    "                        velocity[0,:,:],\n",
    "                        velocity[1,:,:],\n",
    "                        velocity[2,:,:],\n",
    "                        jnp.pad(params['diffusivity_x'], ((0, 0), (1, 0))),\n",
    "                        jnp.pad(params['diffusivity_y'], ((1, 0), (0, 0))),\n",
    "                        inflow_term,\n",
    "                        terrain), axis=-1)  # (26,49,8)\n",
    "\n",
    "    # (26,49,1)\n",
    "    output = closure_net.apply({'params': params['closure']}, input, hidden_state)\n",
    "    # print(jnp.mean(output), jnp.std(output))\n",
    "    closure_term = output * 1e-10        # a denormalization value, from previous tests\n",
    "    smoke_pred = (smoke_pred\\\n",
    "                    + closure_term.squeeze()) * terrain\n",
    "\n",
    "    time_next = time_curr + dt\n",
    "\n",
    "    # smoke_pred = jnp.maximum(smoke_pred, 0.0)\n",
    "\n",
    "    # update hidden states\n",
    "    mean = jnp.mean(smoke_pred)\n",
    "    std = jnp.std(smoke_pred)\n",
    "    input = jnp.stack(((smoke_pred-mean)/std,\n",
    "                        TERRAIN * mean,\n",
    "                        TERRAIN * std), axis=-1)  # (26,49,4)\n",
    "    hidden_pred, cell_pred = hidden_net.apply({'params': params['hidden']}, input, hidden_state, cell_state)   # (128,)\n",
    "\n",
    "    return (smoke_pred, hidden_pred, cell_pred, time_next, params, inflow_loc, inflow_vals), jnp.sum(closure_term**2)\n",
    "\n",
    "step_for_loop = lambda carry, x: conv_diff_single_step(params=carry[4],\n",
    "                                                        smoke_initial=carry[0],\n",
    "                                                        hidden_state=carry[1],\n",
    "                                                        cell_state=carry[2],\n",
    "                                                        velocity=VELOCITY,\n",
    "                                                        time_curr=carry[3],\n",
    "                                                        inflow_loc=carry[5],\n",
    "                                                        inflow_vals=carry[6],\n",
    "                                                        terrain=TERRAIN,\n",
    "                                                        dt=dt)\n",
    "\n",
    "@partial(jax.jit, static_argnames=['nsteps'])\n",
    "def conv_diff_nsteps(params,\n",
    "                     smoke_initial: jnp.array,\n",
    "                     hidden_initial: jnp.array,\n",
    "                     cell_initial: jnp.array,\n",
    "                     time_initial,\n",
    "                     inflow_loc,\n",
    "                     inflow_vals,\n",
    "                     nsteps):\n",
    "    (smoke_pred, hidden_pred, cell_pred, _, params, _, _), _ = jax.lax.scan(step_for_loop, (smoke_initial, hidden_initial, cell_initial, time_initial, params, inflow_loc, inflow_vals), xs=None, length=nsteps)\n",
    "    return smoke_pred, hidden_pred, cell_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1754886553566,
     "user": {
      "displayName": "Tingkai Xue",
      "userId": "03772826909779438587"
     },
     "user_tz": -480
    },
    "id": "WcJnLHxSuA5B"
   },
   "outputs": [],
   "source": [
    "def create_train_state(params_nn, params_physics, learning_rate):\n",
    "    params = {}\n",
    "    params['closure'] = params_nn['closure']\n",
    "    params['hidden'] = params_nn['hidden']\n",
    "    params['inflow'] = params_nn['inflow']\n",
    "    params['diffusivity_x'] = params_physics['diffusivity_x']\n",
    "    params['diffusivity_y'] = params_physics['diffusivity_y']\n",
    "\n",
    "    tx = optax.adam(learning_rate)\n",
    "    return train_state.TrainState.create(apply_fn=None,\n",
    "                                         params=params,\n",
    "                                         tx=tx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16959,
     "status": "ok",
     "timestamp": 1754886570531,
     "user": {
      "displayName": "Tingkai Xue",
      "userId": "03772826909779438587"
     },
     "user_tz": -480
    },
    "id": "wEKhVQxtvsoC",
    "outputId": "1322eb33-6577-4325-9327-b389056a7aff"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipython-input-3934093557.py:2: DeprecationWarning: Pickled array contains an aval with a named_shape attribute. This is deprecated and the code path supporting such avals will be removed. Please re-pickle the array.\n",
      "  params_physics = pickle.load(handle)\n"
     ]
    }
   ],
   "source": [
    "with open(f'{dir}/dataset/diffusivity.pickle', 'rb') as handle:\n",
    "    params_physics = pickle.load(handle)\n",
    "\n",
    "params_nn = {}\n",
    "params_nn['closure'] = closure_net.init(jax.random.PRNGKey(0), jnp.zeros((ny, nx, 10)), [jnp.zeros((128,)), jnp.zeros((128,)), jnp.zeros((128,)), jnp.zeros((128,))])['params']\n",
    "params_nn['hidden'] = hidden_net.init(jax.random.PRNGKey(0), jnp.zeros((ny, nx, 3)), [jnp.zeros((128,)), jnp.zeros((128,)), jnp.zeros((128,)), jnp.zeros((128,))], [jnp.zeros((128,)), jnp.zeros((128,)), jnp.zeros((128,)), jnp.zeros((128,))])['params']\n",
    "params_nn['inflow'] = inflow_net.init(jax.random.PRNGKey(0), jnp.zeros((1, ny, nx, 7)))['params']\n",
    "\n",
    "state = create_train_state(params_nn=params_nn, params_physics=params_physics,learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AWVa3Q-g2Rdt"
   },
   "source": [
    "________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-npJJjxXN2A"
   },
   "outputs": [],
   "source": [
    "@jax.jit\n",
    "def conv_diff_single_step(params,\n",
    "                          smoke_initial: jnp.array,\n",
    "                          hidden_state: jnp.array,\n",
    "                          cell_state: jnp.array,\n",
    "                          velocity: jnp.array,\n",
    "                          time_curr: float,\n",
    "                          inflow_loc: jnp.array,\n",
    "                          inflow_vals: jnp.array,\n",
    "                          terrain: jnp.array,\n",
    "                          dt: float):\n",
    "    y,x = inflow_loc\n",
    "    inflow_marker = jnp.zeros((26,49))\n",
    "    for i in range(len(REL_LOC)):\n",
    "        rel_y, rel_x = REL_LOC[i]\n",
    "\n",
    "        # set smoke at inflow locations\n",
    "        inflow_marker = inflow_marker.at[y+rel_y, x+rel_x].set(1.0)\n",
    "\n",
    "    # compute inflow term\n",
    "    input = jnp.stack((terrain,\n",
    "                       velocity[0,:,:],\n",
    "                       velocity[1,:,:],\n",
    "                       velocity[2,:,:],\n",
    "                       jnp.pad(params['diffusivity_x'], ((0, 0), (1, 0))),\n",
    "                       jnp.pad(params['diffusivity_y'], ((1, 0), (0, 0))),\n",
    "                       inflow_marker), axis=-1) #(4,)\n",
    "    inflow = inflow_net.apply({'params': params['inflow']}, input)\n",
    "    inflow_term = jnp.zeros((26,49))\n",
    "    for i in range(len(REL_LOC)):\n",
    "        rel_y, rel_x = REL_LOC[i]\n",
    "        inflow_term = inflow_term.at[y+rel_y, x+rel_x].set(inflow[i])\n",
    "\n",
    "    smoke_pred = smoke_initial\n",
    "    advection_term = jnp.zeros((ny, nx))\n",
    "    diffusion_term = jnp.zeros((ny, nx))\n",
    "\n",
    "    for _ in range(NSUBSTEPS):\n",
    "      advection_step = physics.advect_fvm(field=smoke_pred,\n",
    "                                              velocity=velocity,\n",
    "                                              dx=dx,\n",
    "                                              dy=dy) * dt/NSUBSTEPS\n",
    "\n",
    "      diffusion_step = physics.diffuse_2d_fvm(field=smoke_pred,\n",
    "                                              diffusivity_x=params['diffusivity_x'],\n",
    "                                              diffusivity_y=params['diffusivity_y'],\n",
    "                                              dx=dx,\n",
    "                                              dy=dy) * dt/NSUBSTEPS\n",
    "\n",
    "      inflow_step = inflow_term * dt/NSUBSTEPS\n",
    "      smoke_pred = smoke_pred + advection_step + diffusion_step + inflow_step\n",
    "      advection_term = advection_term + advection_step\n",
    "      diffusion_term = diffusion_term + diffusion_step\n",
    "\n",
    "    # compute closure term\n",
    "    smoke_mean = jnp.mean(smoke_initial)\n",
    "    eps = 1e-8\n",
    "    smoke_std = jnp.std(smoke_initial)\n",
    "    smoke_std_safe = jnp.where(smoke_std > eps, smoke_std, eps)\n",
    "    input = jnp.stack(((smoke_initial-smoke_mean)/smoke_std_safe,\n",
    "                        terrain * smoke_mean,\n",
    "                        terrain * smoke_std,\n",
    "                        velocity[0,:,:],\n",
    "                        velocity[1,:,:],\n",
    "                        velocity[2,:,:],\n",
    "                        jnp.pad(params['diffusivity_x'], ((0, 0), (1, 0))),\n",
    "                        jnp.pad(params['diffusivity_y'], ((1, 0), (0, 0))),\n",
    "                        inflow_term,\n",
    "                        terrain), axis=-1)  # (26,49,8)\n",
    "\n",
    "    # (26,49,1)\n",
    "    output = closure_net.apply({'params': params['closure']}, input, hidden_state)\n",
    "    # print(jnp.mean(output), jnp.std(output))\n",
    "    closure_term = output * 1e-10        # a denormalization value, from previous tests\n",
    "    smoke_pred = (smoke_pred\\\n",
    "                    + closure_term.squeeze()) * terrain\n",
    "\n",
    "    time_next = time_curr + dt\n",
    "\n",
    "    # smoke_pred = jnp.maximum(smoke_pred, 0.0)\n",
    "\n",
    "    # update hidden states\n",
    "    mean = jnp.mean(smoke_pred)\n",
    "    std = jnp.std(smoke_pred)\n",
    "    input = jnp.stack(((smoke_pred-mean)/std,\n",
    "                        TERRAIN * mean,\n",
    "                        TERRAIN * std), axis=-1)  # (26,49,4)\n",
    "    hidden_pred, cell_pred = hidden_net.apply({'params': params['hidden']}, input, hidden_state, cell_state)   # (128,)\n",
    "\n",
    "    return (smoke_pred, hidden_pred, cell_pred, time_next, params, inflow_loc, inflow_vals, advection_term, diffusion_term, closure_term, inflow_term), None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{dir}/trained_models/expt1_baseline_rep1.pickle', 'rb') as bunch:\n",
    "  state_dict = pickle.load(bunch)\n",
    "state = flax.serialization.from_state_dict(state, state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "if7DUQftLAcZ"
   },
   "outputs": [],
   "source": [
    "# with jax.disable_jit():\n",
    "for set_idx in range(len(SMOKE_FIELD)):\n",
    "\n",
    "  smoke_terms = []\n",
    "  advection_terms = []\n",
    "  diffusion_terms = []\n",
    "  closure_terms = []\n",
    "  error_terms = []\n",
    "  rel_error_terms = []\n",
    "  inflow_terms = []\n",
    "  hidden_terms = []\n",
    "\n",
    "  smoke_curr = SMOKE_FIELD[set_idx][0]\n",
    "  time_curr = FLOW_TIMES[set_idx][0]\n",
    "  hidden_curr, cell_curr = jnp.zeros((4,128)), jnp.zeros((4,128))\n",
    "\n",
    "  n = len(FLOW_TIMES[set_idx])-1\n",
    "  for times_idx in range(len(FLOW_TIMES[set_idx])-1):\n",
    "    nsteps = int((FLOW_TIMES[set_idx][times_idx+1]-FLOW_TIMES[set_idx][times_idx]+1e-3)/dt)\n",
    "\n",
    "    for i in range(nsteps):\n",
    "      (smoke_curr, hidden_curr, cell_curr, time_curr, _, _, _, advection_term, diffusion_term, closure_term, inflow_term), _ = conv_diff_single_step(params=state.params,\n",
    "                                                                                                                                smoke_initial=smoke_curr,\n",
    "                                                                                                                                hidden_state=hidden_curr,\n",
    "                                                                                                                                cell_state=cell_curr,\n",
    "                                                                                                                                velocity=VELOCITY,\n",
    "                                                                                                                                time_curr=time_curr,\n",
    "                                                                                                                                inflow_loc=INFLOW_LOCS[set_idx],\n",
    "                                                                                                                                inflow_vals=INFLOW_VALS[set_idx],\n",
    "                                                                                                                                terrain=TERRAIN,\n",
    "                                                                                                                                dt=dt)\n",
    "      smoke_terms.append(smoke_curr)\n",
    "      advection_terms.append(advection_term)\n",
    "      diffusion_terms.append(diffusion_term)\n",
    "      closure_terms.append(closure_term)\n",
    "      inflow_terms.append(inflow_term)\n",
    "      error_terms.append(optax.l2_loss(smoke_curr, SMOKE_FIELD[set_idx][times_idx+1]))\n",
    "      hidden_terms.append(hidden_curr)\n",
    "\n",
    "      denom = SMOKE_FIELD[set_idx][times_idx+1]\n",
    "      loss1 = optax.l2_loss(smoke_curr, SMOKE_FIELD[set_idx][times_idx+1])/(SMOKE_FIELD[set_idx][times_idx+1]+1e-9)**2\n",
    "      rel_error_terms.append(loss1)\n",
    "\n",
    "\n",
    "  with open(f'{dir}/videos/22072025_{INFLOW_LOCS[set_idx]}_smoke.pickle', 'wb') as f:\n",
    "    pickle.dump(smoke_terms, f)\n",
    "  with open(f'{dir}/videos/22072025_{INFLOW_LOCS[set_idx]}_advection.pickle', 'wb') as f:\n",
    "    pickle.dump(advection_terms, f)\n",
    "  with open(f'{dir}/videos/22072025_{INFLOW_LOCS[set_idx]}_diffusion.pickle', 'wb') as f:\n",
    "    pickle.dump(diffusion_terms, f)\n",
    "  with open(f'{dir}/videos/22072025_{INFLOW_LOCS[set_idx]}_closure.pickle', 'wb') as f:\n",
    "    pickle.dump(closure_terms, f)\n",
    "  with open(f'{dir}/videos/22072025_{INFLOW_LOCS[set_idx]}_inflow.pickle', 'wb') as f:\n",
    "    pickle.dump(inflow_terms, f)\n",
    "  with open(f'{dir}/videos/22072025_{INFLOW_LOCS[set_idx]}_relerror.pickle', 'wb') as f:\n",
    "    pickle.dump(rel_error_terms, f)\n",
    "  with open(f'{dir}/videos/22072025_{INFLOW_LOCS[set_idx]}_hidden.pickle', 'wb') as f:\n",
    "    pickle.dump(hidden_terms, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ky8vvAcimICs"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R3GtV4Av58Co"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMLAnuUBXehAPHDt0fsjM5p",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
